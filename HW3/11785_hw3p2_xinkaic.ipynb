{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11785-hw3p2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zy5NfbrepRv"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"xinkaichen97\",\"key\":\"a31b1965f229c3f21b0282be2d9cdd3f\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/\n",
        "!kaggle config path -p /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHGL7DqoesF3"
      },
      "source": [
        "!pip install ipdb\n",
        "import os, zipfile, tarfile, ipdb\n",
        "os.environ['KAGGLE_USERNAME'] = \"xinkaichen97\" \n",
        "os.environ['KAGGLE_KEY'] = \"a31b1965f229c3f21b0282be2d9cdd3f\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHHn33usetGu"
      },
      "source": [
        "!kaggle competitions download -c 11-785-fall-20-homework-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jc1-ZX0fj0u"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"train.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"train_labels.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"dev.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"dev_labels.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"test.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U1lMzcOHtlR"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1zE_eASyU0d"
      },
      "source": [
        "!pip install torch_edit_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_fDaYiif3RG"
      },
      "source": [
        "!pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66DbvS5BhDqe"
      },
      "source": [
        "import numpy as np\n",
        "import Levenshtein\n",
        "# import torch_edit_distance\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from torch.nn import CTCLoss\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from phoneme_list import PHONEME_LIST, PHONEME_MAP\n",
        "from ctcdecode import CTCBeamDecoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUQFH9xhGgL",
        "outputId": "555a1aca-03b6-42cc-d41e-4bd625dc4146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSElQh25hG3i"
      },
      "source": [
        "train_features = np.load('train.npy', allow_pickle=True)\n",
        "dev_features = np.load('dev.npy', allow_pickle=True)\n",
        "test_features = np.load('test.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUECH7WChgJV"
      },
      "source": [
        "train_labels = np.load('train_labels.npy', allow_pickle=True)\n",
        "dev_labels = np.load('dev_labels.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxMnKT8YhZ-d"
      },
      "source": [
        "print(train_features[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMoQ-Cy_hxSJ"
      },
      "source": [
        "print(train_labels[0].shape, train_labels[100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fqWK7txnp_V"
      },
      "source": [
        "print(len(PHONEME_LIST), PHONEME_LIST)\n",
        "print(len(PHONEME_MAP), PHONEME_MAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4HL65k2LysC"
      },
      "source": [
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, inputs, labels):\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        X = self.inputs[idx]\n",
        "        Y = self.labels[idx] + 1\n",
        "        return torch.from_numpy(X), torch.from_numpy(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtiICLdrPP2o"
      },
      "source": [
        "def collate_fn(data):\n",
        "  feature_lst = [item[0] for item in data]\n",
        "  label_lst = [item[1] for item in data]\n",
        "  features = rnn.pad_sequence(feature_lst)\n",
        "  labels = rnn.pad_sequence(label_lst, batch_first=True)\n",
        "  feature_lengths = torch.tensor([sample.shape[0] for sample in feature_lst])\n",
        "  label_lengths = torch.tensor([sample.shape[0] for sample in label_lst])\n",
        "  return features.float(), labels.long(), feature_lengths.long(), label_lengths.long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNpjMaHqN8v-"
      },
      "source": [
        "train_dataset = SpeechDataset(train_features, train_labels)\n",
        "dev_dataset = SpeechDataset(dev_features, dev_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVY3Tdb2TXwP"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouBRK0mQOBk1"
      },
      "source": [
        "print(len(dev_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPyrILL4Ty_g"
      },
      "source": [
        "# baseline\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=13, hidden_size=256, num_layers=3, bidirectional=True)\n",
        "        self.fc = nn.Linear(512, 42)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.lstm(x)[0]\n",
        "        y, lens = rnn.pad_packed_sequence(y)\n",
        "        y = self.fc(y).log_softmax(2)\n",
        "        # y = F.log_softmax(y)\n",
        "        return y, lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvUTd879ZvyI"
      },
      "source": [
        "# final model\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels=13, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.lstm = nn.LSTM(input_size=32, hidden_size=512, num_layers=4, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 42)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = x.permute(1, 2, 0)\n",
        "        x = self.conv(x)\n",
        "        x = x.permute(2, 0, 1)\n",
        "        packed_x = rnn.pack_padded_sequence(x, lengths, enforce_sorted=False)\n",
        "        y = self.lstm(packed_x)[0]\n",
        "        y, lens = rnn.pad_packed_sequence(y)\n",
        "        y = self.fc1(y)\n",
        "        y = self.fc2(y).log_softmax(2)\n",
        "        return y, lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqugXsW8pjCN"
      },
      "source": [
        "# bigger model (didn't reach A cutoff)\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=13, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.lstm = nn.LSTM(input_size=32, hidden_size=512, num_layers=5, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 42)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = x.permute(1, 2, 0)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.permute(2, 0, 1)\n",
        "        packed_x = rnn.pack_padded_sequence(x, lengths, enforce_sorted=False)\n",
        "        y = self.lstm(packed_x)[0]\n",
        "        y, lens = rnn.pad_packed_sequence(y)\n",
        "        y = self.fc1(y)\n",
        "        y = self.fc2(y).log_softmax(2)\n",
        "        return y, lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PcDQI0ZT0C"
      },
      "source": [
        "model = Net().cuda()\n",
        "criterion = nn.CTCLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-6)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYbLk1e3b9p5"
      },
      "source": [
        "# validation\n",
        "def validate(model, val_loader):\n",
        "    total_distance = 0\n",
        "    count = 0\n",
        "    for i, (batch_data, batch_labels, feature_lengths, _) in enumerate(val_loader):\n",
        "        batch_data = batch_data.cuda()\n",
        "        feature_lengths = feature_lengths.cuda()\n",
        "        with torch.no_grad():\n",
        "          outputs, output_lens = model(batch_data, feature_lengths)\n",
        "        decoder = CTCBeamDecoder(labels=PHONEME_MAP, beam_width=10, log_probs_input=True)\n",
        "        beam_results, beam_scores, timesteps, out_lens = decoder.decode(outputs.transpose(0, 1).cpu(), output_lens.cpu())\n",
        "        # for each example in the batch\n",
        "        for j in range(batch_data.shape[1]):\n",
        "          out_labels = beam_results[j][0][:out_lens[j][0]]\n",
        "          pred = \"\".join([PHONEME_MAP[n] for n in out_labels])\n",
        "          actual = \"\".join([PHONEME_MAP[n] for n in batch_labels[j]])\n",
        "          distance = Levenshtein.distance(pred, actual)\n",
        "          total_distance += distance\n",
        "          count += 1\n",
        "        torch.cuda.empty_cache()\n",
        "        del batch_data\n",
        "        del batch_labels\n",
        "        del feature_lengths\n",
        "    assert count == 2332\n",
        "    avg_distance = total_distance / count\n",
        "    return avg_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9tUWr1XacbC",
        "outputId": "980bf637-b3e4-4a20-8f13-84fd1d5a388b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training\n",
        "val_distances = []\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for i, (batch_data, batch_labels, feature_lengths, label_lengths) in enumerate(train_loader):\n",
        "        batch_data = batch_data.cuda()\n",
        "        # batch_labels = batch_labels.cuda()\n",
        "        feature_lengths = feature_lengths.cuda()\n",
        "        # label_lengths = label_lengths.cuda()        \n",
        "        optimizer.zero_grad()\n",
        "        outputs, out_lens = model(batch_data, feature_lengths)\n",
        "        loss = criterion(outputs, batch_labels.cuda(), out_lens, label_lengths.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = 0.0\n",
        "        running_loss += loss.item()\n",
        "        epoch_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.10f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "        torch.cuda.empty_cache()\n",
        "        del batch_data\n",
        "        del batch_labels\n",
        "        del feature_lengths\n",
        "        del label_lengths\n",
        "        del loss\n",
        "    print(epoch_loss / 343)\n",
        "    scheduler.step()\n",
        "    # if epoch % 5 == 4:\n",
        "    # val_dist = validate(model, dev_loader)\n",
        "    # print(val_dist)\n",
        "    # val_distances.append(val_dist)\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 0.0004416916\n",
            "[1,   200] loss: 0.0005748497\n",
            "[1,   300] loss: 0.0005436538\n",
            "0.0524900309285339\n",
            "[2,   100] loss: 0.0003537426\n",
            "[2,   200] loss: 0.0003872909\n",
            "[2,   300] loss: 0.0004654157\n",
            "0.039893587296367036\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56qzdZ7uarVA"
      },
      "source": [
        "torch.save(model.state_dict(), \"model_e25.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpE5kmF8DesH"
      },
      "source": [
        "model.load_state_dict(torch.load('model_bigger_e25.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c1GPoBmvlDm"
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, inputs):\n",
        "        self.inputs = inputs\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        X = self.inputs[idx]\n",
        "        return torch.from_numpy(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSVORhrRDJWc"
      },
      "source": [
        "def collate_fn_test(data):\n",
        "  feature_lst = [item for item in data]\n",
        "  features = rnn.pad_sequence(feature_lst)\n",
        "  feature_lengths = torch.tensor([sample.shape[0] for sample in feature_lst])\n",
        "  return features.float(), feature_lengths.long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBj2ZusXC1VB"
      },
      "source": [
        "test_dataset = TestDataset(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOK8spJKDDmp"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiogV0QOvpF1"
      },
      "source": [
        "# prediction\n",
        "def predict(model, test_loader):\n",
        "    preds = []\n",
        "    for i, (batch_data, feature_lengths) in enumerate(test_loader):\n",
        "        batch_data = batch_data.cuda()\n",
        "        feature_lengths = feature_lengths.cuda()   \n",
        "        with torch.no_grad():\n",
        "          outputs, output_lens = model(batch_data, feature_lengths)\n",
        "        decoder = CTCBeamDecoder(labels=PHONEME_MAP, beam_width=100, log_probs_input=True)\n",
        "        beam_results, beam_scores, timesteps, out_lens = decoder.decode(outputs.transpose(0, 1).cpu(), seq_lens=output_lens.cpu())\n",
        "        for j in range(batch_data.shape[1]):\n",
        "          out_labels = beam_results[j][0][:out_lens[j][0]]\n",
        "          pred = \"\".join([PHONEME_MAP[n] for n in out_labels])\n",
        "          preds.append(pred)\n",
        "        torch.cuda.empty_cache()\n",
        "        del batch_data\n",
        "        del feature_lengths\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FU48KYwDVB7"
      },
      "source": [
        "preds = predict(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWqh2EYlDZt0",
        "outputId": "6d444b5a-9f89-4000-e614-3999d2747dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(preds), preds[2000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2251 .ykhmnwthDIhDrkeRhktrhstikHWic.memrIimhjizmhstHAf.inoRdrthDhkwntfraRnalijhvDhpAst.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6dU90Qvgf9w"
      },
      "source": [
        "# generate submission.csv\n",
        "with open('submission.csv', 'w') as f:\n",
        "  f.write('id,label\\n')\n",
        "  for i in range(len(preds)):\n",
        "    f.write(str(i) + ',' + preds[i]+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdYLICb2e3S4",
        "outputId": "6bb039f4-7fa4-4507-c142-62eccd56ae82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle competitions submit -c 11-785-fall-20-homework-3 -f submission.csv -m \"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "100% 174k/174k [00:02<00:00, 59.8kB/s]\n",
            "Successfully submitted to 11-785-Fall-20-Homework 3 "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}