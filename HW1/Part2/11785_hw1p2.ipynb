{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11785-hw1p2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfl0rJuwedj0"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"xinkaichen97\",\"key\":\"a31b1965f229c3f21b0282be2d9cdd3f\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/\n",
        "!kaggle config path -p /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsYXamEketvk"
      },
      "source": [
        "!pip install ipdb\n",
        "import os, zipfile, tarfile, ipdb\n",
        "os.environ['KAGGLE_USERNAME'] = \"xinkaichen97\" \n",
        "os.environ['KAGGLE_KEY'] = \"a31b1965f229c3f21b0282be2d9cdd3f\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2GTo0GDew0D"
      },
      "source": [
        "!kaggle competitions download -c 11-785-fall-20-homework-1-part-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8kknsE7e1gK"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"train.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"train_labels.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"dev.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"dev_labels.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"test.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"sample.csv.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvKlfjnee3kp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBHucX_Fe5wk",
        "outputId": "d3b0c39b-cd04-4ddc-e102-896adac92b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A9p6vAEfAQT"
      },
      "source": [
        "class CorrectDataset(Dataset):\n",
        "    def __init__(self, features_file, labels_file, context_size):\n",
        "        self.inputs = np.load(features_file, allow_pickle=True)\n",
        "        self.indices_dict = self.get_indices()\n",
        "        self.pad_utterances(context_size)\n",
        "        print(self.inputs[0].shape)\n",
        "        self.labels = np.load(labels_file, allow_pickle=True)\n",
        "        print(self.labels.shape)\n",
        "        print(len(self.indices_dict.keys()))\n",
        "        self.context_size = context_size\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.indices_dict.keys())\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        utter_idx, within_utter_idx = self.indices_dict[idx]\n",
        "        within_utter_idx_pad = within_utter_idx + self.context_size\n",
        "        return torch.flatten(self.inputs[utter_idx][within_utter_idx_pad - self.context_size: within_utter_idx_pad + self.context_size + 1, :]), self.labels[utter_idx][within_utter_idx]\n",
        "\n",
        "    def get_indices(self):\n",
        "        total = 0\n",
        "        indices_dict = {}\n",
        "        for i in range(len(self.inputs)):\n",
        "            utterance = self.inputs[i]\n",
        "            for j in range(len(utterance)):\n",
        "                indices_dict[total + j] = (i, j)\n",
        "            total += len(utterance)\n",
        "        print(total)\n",
        "        return indices_dict\n",
        "    \n",
        "    def pad_utterances(self, context_size):\n",
        "        for i in range(len(self.inputs)):\n",
        "            self.inputs[i] = F.pad(input=torch.Tensor(self.inputs[i]), pad=(0,0,context_size,context_size), mode='constant', value=0)\n",
        "    \n",
        "    def get_context(self, utterance, i, context_size):\n",
        "        return torch.flatten(utterance[i - context_size: i + context_size + 1, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eMmwxx-fE-c"
      },
      "source": [
        "train_dataset = CorrectDataset(features_file='train.npy', labels_file='train_labels.npy', context_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWbj5Gbfbwf"
      },
      "source": [
        "print(train_dataset[3190][0].shape)\n",
        "print(len(train_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xc8tKt93NMi"
      },
      "source": [
        "dev_dataset = CorrectDataset(features_file='dev.npy', labels_file='dev_labels.npy', context_size=20)\n",
        "devloader = DataLoader(dev_dataset, batch_size=5000, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv2t5ouffIHW"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear((1 + 2 * 20) * 13, 1024)\n",
        "        self.bn1 = nn.BatchNorm1d(1024)  \n",
        "        self.fc2 = nn.Linear(1024, 2048)\n",
        "        self.bn2 = nn.BatchNorm1d(2048) \n",
        "        self.fc3 = nn.Linear(2048, 2048)\n",
        "        self.bn3 = nn.BatchNorm1d(2048)\n",
        "        self.fc4 = nn.Linear(2048, 1024)\n",
        "        self.bn4 = nn.BatchNorm1d(1024)\n",
        "        self.fc5 = nn.Linear(1024, 346)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.bn1(F.relu(self.fc1(x)))\n",
        "        y = self.bn2(F.relu(self.fc2(y)))\n",
        "        y = self.bn3(F.relu(self.fc3(y)))\n",
        "        y = self.bn3(F.relu(self.fc3(y)))\n",
        "        y = self.bn4(F.relu(self.fc4(y)))\n",
        "        y = self.fc5(y)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ePLUsuf0ij"
      },
      "source": [
        "dataloader = DataLoader(train_dataset, batch_size=5000, shuffle=True, num_workers=4)\n",
        "model = Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24Bg-7Ef3-j"
      },
      "source": [
        "# training\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    if epoch % 2 == 1:\n",
        "      scheduler.step()  \n",
        "    for i, (batch_data, batch_labels) in enumerate(dataloader):\n",
        "        batch_labels = batch_labels.cuda()\n",
        "        batch_data = batch_data.cuda()\n",
        "        running_loss = 0.0\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(batch_data)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            train_losses.append(running_loss)\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "    val_accuracies.append(validate(devloader))\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHrT77hW3h6p"
      },
      "source": [
        "# validation\n",
        "def validate(devloader):\n",
        "    num_correct = 0\n",
        "    for i, (batch_data, batch_labels) in enumerate(devloader):\n",
        "            batch_labels = batch_labels.cuda()\n",
        "            batch_data = batch_data.cuda()\n",
        "            outputs = model(batch_data)\n",
        "            pred = torch.argmax(outputs, dim=1)\n",
        "            current_correct = len([pred[i] for i in range(len(pred)) if pred[i] == batch_labels[i]])\n",
        "            num_correct += current_correct\n",
        "    accuracy = num_correct / len(dev_dataset)\n",
        "return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P-mQ9XNihxY"
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, features_file, context_size):\n",
        "        self.inputs = np.load(features_file, allow_pickle=True)\n",
        "        self.indices_dict = self.get_indices()\n",
        "        self.pad_utterances(context_size)\n",
        "        self.context_size = context_size\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.indices_dict.keys())\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        utter_idx, within_utter_idx = self.indices_dict[idx]\n",
        "        within_utter_idx_pad = within_utter_idx + self.context_size\n",
        "        return torch.flatten(self.inputs[utter_idx][within_utter_idx_pad - self.context_size: within_utter_idx_pad + self.context_size + 1, :])\n",
        "    \n",
        "    def get_indices(self):\n",
        "        total = 0\n",
        "        indices_dict = {}\n",
        "        for i in range(len(self.inputs)):\n",
        "            utterance = self.inputs[i]\n",
        "            for j in range(len(utterance)):\n",
        "                indices_dict[total + j] = (i, j)\n",
        "            total += len(utterance)\n",
        "        print(total)\n",
        "        return indices_dict\n",
        "    \n",
        "    def pad_utterances(self, context_size):\n",
        "        for i in range(len(self.inputs)):\n",
        "            self.inputs[i] = F.pad(input=torch.Tensor(self.inputs[i]), pad=(0,0,context_size,context_size), mode='constant', value=0)\n",
        "    \n",
        "    def get_context(self, utterance, i, context_size):\n",
        "        return torch.flatten(utterance[i - context_size: i + context_size + 1, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwBT6ahLmpXf"
      },
      "source": [
        "torch.save(model.state_dict(), \"model_20_bigger.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S__yarQ6j3rs",
        "outputId": "68244d01-3a26-420a-ad7a-70bc3e4784bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "test_set = TestDataset(features_file='test.npy', context_size=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1593223\n",
            "torch.Size([365, 13])\n",
            "1593223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkD-crH_x0kU"
      },
      "source": [
        "testloader = DataLoader(test_set, batch_size=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZEO7S_5ywJj"
      },
      "source": [
        "# get test predictions\n",
        "total_preds = np.array([])\n",
        "for i, batch_data in enumerate(testloader):\n",
        "  batch_data = batch_data.cuda()\n",
        "  outputs = model(batch_data)\n",
        "  pred = np.argmax(outputs.cpu().detach().numpy(), axis=1)\n",
        "  total_preds = np.append(total_preds, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbpaw0ltzERk"
      },
      "source": [
        "# generate submission.csv\n",
        "with open('submission.csv', 'w') as f:\n",
        "  f.write('id,label\\n')\n",
        "  for i, label in enumerate(total_preds):\n",
        "    f.write(str(i) + ',' + str(int(label)) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiqQP7BZKYVh"
      },
      "source": [
        "!kaggle competitions submit -c 11-785-fall-20-homework-1-part-2 -f submission.csv -m \"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}