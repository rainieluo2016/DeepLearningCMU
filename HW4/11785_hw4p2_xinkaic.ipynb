{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "11785-hw4p2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OctIyl34dHLj",
        "outputId": "533c83d3-749b-4511-f582-698745ff3619"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"xinkaichen97\",\"key\":\"a31b1965f229c3f21b0282be2d9cdd3f\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/\n",
        "!kaggle config path -p /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            "usage: kaggle config [-h] {view,set,unset} ...\n",
            "kaggle config: error: argument command: invalid choice: 'path' (choose from 'view', 'set', 'unset')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7jxgMH3dIkp",
        "outputId": "59a10e72-bd30-4cf2-c17b-56996ba17158"
      },
      "source": [
        "!pip install ipdb\n",
        "import os, zipfile, tarfile, ipdb\n",
        "os.environ['KAGGLE_USERNAME'] = \"xinkaichen97\" \n",
        "os.environ['KAGGLE_KEY'] = \"a31b1965f229c3f21b0282be2d9cdd3f\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/44/8c/76b33b115f4f2c090e2809a0247fe777eb3832f9d606479bf0139b29ca2c/ipdb-0.13.4.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (50.3.2)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.6.0)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.4-cp36-none-any.whl size=10973 sha256=c378793b8a057b51e9dab52af1bb055437f82699a7a135e3cb179e363cbfe120\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/51/e4/c91c61e3481a1a967beb18c4ea7a2b138a63cce94170b2e206\n",
            "Successfully built ipdb\n",
            "Installing collected packages: ipdb\n",
            "Successfully installed ipdb-0.13.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGvH3xDc1V9l",
        "outputId": "056313b1-5cb9-4ddf-d7dc-c5382db214c6"
      },
      "source": [
        "!kaggle competitions download -c 11-785-fall-20-homework-4-part-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "Downloading test.npy.zip to /content\n",
            " 89% 162M/183M [00:02<00:00, 45.0MB/s]\n",
            "100% 183M/183M [00:02<00:00, 82.5MB/s]\n",
            "Downloading train.npy.zip to /content\n",
            "100% 3.36G/3.36G [00:30<00:00, 125MB/s]\n",
            "100% 3.36G/3.36G [00:30<00:00, 120MB/s]\n",
            "Downloading sample.csv to /content\n",
            "  0% 0.00/16.8k [00:00<?, ?B/s]\n",
            "100% 16.8k/16.8k [00:00<00:00, 15.1MB/s]\n",
            "Downloading dev_transcripts.npy to /content\n",
            "  0% 0.00/784k [00:00<?, ?B/s]\n",
            "100% 784k/784k [00:00<00:00, 105MB/s]\n",
            "Downloading train_transcripts.npy.zip to /content\n",
            "  0% 0.00/3.76M [00:00<?, ?B/s]\n",
            "100% 3.76M/3.76M [00:00<00:00, 255MB/s]\n",
            "Downloading dev.npy.zip to /content\n",
            " 89% 161M/182M [00:01<00:00, 112MB/s]\n",
            "100% 182M/182M [00:01<00:00, 130MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGQWGqxkZEVe"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"train.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"train_transcripts.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"dev.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")\n",
        "# with zipfile.ZipFile(\"dev_transcripts.npy.zip\",\"r\") as z:\n",
        "#   z.extractall(\".\")\n",
        "with zipfile.ZipFile(\"test.npy.zip\",\"r\") as z:\n",
        "  z.extractall(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5GHQnmQ-C9A",
        "outputId": "c051e747-4aa6-4e83-c922-d89fffd5a09c"
      },
      "source": [
        "!pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 23.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (50.3.2)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144802 sha256=868afe88f1a3490e2a051fc2db4575208a3273dd6024f31fdcaafe1375dbd514\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKBptCIp1LXb"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils as utils\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.distributions.gumbel import Gumbel\n",
        "from Levenshtein import distance as levenshtein_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zZveymwaAvN"
      },
      "source": [
        "speech_train = np.load('train.npy', allow_pickle=True, encoding='bytes')\n",
        "speech_valid = np.load('dev.npy', allow_pickle=True, encoding='bytes')\n",
        "speech_test = np.load('test.npy', allow_pickle=True, encoding='bytes')\n",
        "transcript_train = np.load('train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
        "transcript_valid = np.load('dev_transcripts.npy', allow_pickle=True,encoding='bytes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq2om0Pharbk",
        "outputId": "59dbb101-439e-420a-bc67-e0e1d61dfc57"
      },
      "source": [
        "len(transcript_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28539"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyZEfF0vaIUG",
        "outputId": "928da551-aea5-4914-b43e-c296eb63dbe5"
      },
      "source": [
        "transcript_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'he', b'had', b'never', b'before', b'come', b'in', b'contact',\n",
              "       b'with', b'such', b'an', b'agreeable', b'lot', b'of',\n",
              "       b'companions', b'and', b'every', b'hour', b'of', b'the', b'day',\n",
              "       b'he', b'tried', b'to', b'prove', b'himself', b'grateful',\n",
              "       b'still', b'he', b'did', b'not', b'mention', b'a', b'word',\n",
              "       b'about', b'what', b'he', b'might', b'possibly', b'know', b'of',\n",
              "       b'the', b'dastardly', b'deed'], dtype='|S10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvcyl5QObuSq",
        "outputId": "ada19900-6967-41f6-9350-7b88ff5b03f9"
      },
      "source": [
        "transcript_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e43rBFWtcmn3",
        "outputId": "77c7e40a-5408-46d6-acb7-c942fcd0c851"
      },
      "source": [
        "char_list = ['<sos> ']\n",
        "for word in transcript_train[0]:\n",
        "  word = word.decode('utf-8')\n",
        "  char_list.append(word)\n",
        "  char_list.append(' ')\n",
        "char_list.append(' <eos>')\n",
        "print(''.join(char_list))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> he had never before come in contact with such an agreeable lot of companions and every hour of the day he tried to prove himself grateful still he did not mention a word about what he might possibly know of the dastardly deed  <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvlmD11KcK3y"
      },
      "source": [
        "'''\n",
        "Loading all the numpy files containing the utterance information and text information\n",
        "'''\n",
        "def load_data():\n",
        "    speech_train = np.load('train.npy', allow_pickle=True, encoding='bytes')\n",
        "    speech_valid = np.load('dev.npy', allow_pickle=True, encoding='bytes')\n",
        "    speech_test = np.load('test.npy', allow_pickle=True, encoding='bytes')\n",
        "\n",
        "    transcript_train = np.load('train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
        "    transcript_valid = np.load('dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
        "\n",
        "    return speech_train, speech_valid, speech_test, transcript_train, transcript_valid\n",
        "\n",
        "\n",
        "'''\n",
        "Transforms alphabetical input to numerical input, replace each letter by its corresponding \n",
        "index from letter_list\n",
        "'''\n",
        "def transform_letter_to_index(transcript, letter_list):\n",
        "    '''\n",
        "    :param transcript :(N, ) Transcripts are the text input\n",
        "    :param letter_list: Letter list defined above\n",
        "    :return letter_to_index_list: Returns a list for all the transcript sentence to index\n",
        "    '''\n",
        "    letter_dict = {letter: idx for idx, letter in enumerate(letter_list)}\n",
        "    transcript_indices = []\n",
        "    for text in transcript:\n",
        "        # text_words = []\n",
        "        text_words = [' ']\n",
        "        for word in text:\n",
        "            text_words.append(word.decode('utf-8'))\n",
        "            text_words.append(' ')\n",
        "        text_indices = [letter_dict[char] for char in ''.join(text_words)]\n",
        "        text_indices.insert(0, letter_dict['<sos>'])\n",
        "        text_indices.append(letter_dict['<eos>'])\n",
        "        transcript_indices.append(np.array(text_indices))\n",
        "    return np.array(transcript_indices)\n",
        "\n",
        "\n",
        "'''\n",
        "Optional, create dictionaries for letter2index and index2letter transformations\n",
        "'''\n",
        "def create_dictionaries(letter_list):\n",
        "    letter2index = dict()\n",
        "    index2letter = dict()\n",
        "    return letter2index, index2letter\n",
        "\n",
        "\n",
        "class Speech2TextDataset(Dataset):\n",
        "    '''\n",
        "    Dataset class for the speech to text data, this may need some tweaking in the\n",
        "    getitem method as your implementation in the collate function may be different from\n",
        "    ours. \n",
        "    '''\n",
        "    def __init__(self, speech, text=None, isTrain=True):\n",
        "        self.speech = speech\n",
        "        self.isTrain = isTrain\n",
        "        if (text is not None):\n",
        "            self.text = text\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.speech.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if (self.isTrain == True):\n",
        "            return torch.tensor(self.speech[index].astype(np.float32)), torch.tensor(self.text[index])\n",
        "        else:\n",
        "            return torch.tensor(self.speech[index].astype(np.float32))\n",
        "\n",
        "\n",
        "def collate_train(batch_data):\n",
        "    ### Return the padded speech and text data, and the length of utterance and transcript ###\n",
        "    feature_lst = [item[0] for item in batch_data]\n",
        "    text_lst = [item[1] for item in batch_data]\n",
        "    features = utils.rnn.pad_sequence(feature_lst)\n",
        "    texts = utils.rnn.pad_sequence(text_lst)\n",
        "    feature_lengths = torch.tensor([sample.shape[0] for sample in feature_lst])\n",
        "    text_lengths = torch.tensor([sample.shape[0] for sample in text_lst])\n",
        "    return features.float(), texts.long(), feature_lengths.long(), text_lengths.long()\n",
        "\n",
        "\n",
        "def collate_test(batch_data):\n",
        "    ### Return padded speech and length of utterance ###\n",
        "    feature_lst = [item for item in batch_data]\n",
        "    features = utils.rnn.pad_sequence(feature_lst)\n",
        "    feature_lengths = torch.tensor([sample.shape[0] for sample in feature_lst])\n",
        "    return features.float(), feature_lengths.long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSmf55RJCmWR"
      },
      "source": [
        "# cite from Salesfore model\n",
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self, dropout = 0.5):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self.dropout:\n",
        "            return x\n",
        "        m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - self.dropout)\n",
        "        mask = Variable(m, requires_grad=False) / (1 - self.dropout)\n",
        "        mask = mask.expand_as(x)\n",
        "        return mask * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df_zmLPLcXBi"
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    '''\n",
        "    Attention is calculated using key, value and query from Encoder and decoder.\n",
        "    Below are the set of operations you need to perform for computing attention:\n",
        "        energy = bmm(key, query)\n",
        "        attention = softmax(energy)\n",
        "        context = bmm(attention, value)\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def forward(self, query, key, value, lens):\n",
        "        '''\n",
        "        :param query :(batch_size, hidden_size) Query is the output of LSTMCell from Decoder\n",
        "        :param keys: (batch_size, max_len, encoder_size) Key Projection from Encoder\n",
        "        :param values: (batch_size, max_len, encoder_size) Value Projection from Encoder\n",
        "        :return context: (batch_size, encoder_size) Attended Context\n",
        "        :return attention_mask: (batch_size, max_len) Attention mask that can be plotted  \n",
        "        '''\n",
        "        key_size = key.size(-1)\n",
        "        energy = torch.bmm(key, query.unsqueeze(2)).squeeze(2) / (key_size ** 0.5)\n",
        "        mask = torch.arange(key.size(1)).unsqueeze(0) >= lens.unsqueeze(1)\n",
        "        mask = mask.to(DEVICE)\n",
        "        energy.masked_fill_(mask, -1e9)\n",
        "        attention = F.softmax(energy, dim=1)\n",
        "        context = torch.bmm(attention.unsqueeze(1), value).squeeze(1)\n",
        "        return context, attention\n",
        "\n",
        "\n",
        "class pBLSTM(nn.Module):\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    The length of utterance (speech input) can be hundereds to thousands of frames long.\n",
        "    The Paper reports that a direct LSTM implementation as Encoder resulted in slow convergence,\n",
        "    and inferior results even after extensive training.\n",
        "    The major reason is inability of AttendAndSpell operation to extract relevant information\n",
        "    from a large number of input steps.\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(pBLSTM, self).__init__()\n",
        "        self.blstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True)\n",
        "        self.dropout =  LockedDropout(dropout = 0.5)\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        '''\n",
        "        :param x :(N, T) input to the pBLSTM\n",
        "        :return output: (N, T, H) encoded sequence from pyramidal Bi-LSTM \n",
        "        '''\n",
        "        x, _ = utils.rnn.pad_packed_sequence(x)\n",
        "        if x.shape[0] % 2 != 0:\n",
        "            x = x[:-1,:,:]\n",
        "        outputs = x.permute(1, 0, 2)\n",
        "        outputs = outputs.reshape(outputs.size(0), outputs.size(1) // 2, outputs.size(2) * 2)\n",
        "        outputs = outputs.permute(1, 0, 2)\n",
        "        outputs = self.dropout(outputs)\n",
        "        lens = lens // 2\n",
        "        rnn_inp = utils.rnn.pack_padded_sequence(outputs, lengths=lens, enforce_sorted=False)\n",
        "        outputs, hidden = self.blstm(rnn_inp)\n",
        "        return outputs, hidden, lens\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    Encoder takes the utterances as inputs and returns the key and value.\n",
        "    Key and value are nothing but simple projections of the output from pBLSTM network.\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim, value_size=128,key_size=128):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True).to(DEVICE)\n",
        "        \n",
        "        ### Add code to define the blocks of pBLSTMs! ###\n",
        "        self.pBLSTM1 = pBLSTM(hidden_dim*4, hidden_dim)\n",
        "        self.pBLSTM2 = pBLSTM(hidden_dim*4, hidden_dim)\n",
        "        self.pBLSTM3 = pBLSTM(hidden_dim*4, hidden_dim)\n",
        "        self.key_network = nn.Linear(hidden_dim*2, value_size).to(DEVICE)\n",
        "        self.value_network = nn.Linear(hidden_dim*2, key_size).to(DEVICE)\n",
        "        \n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        rnn_inp = utils.rnn.pack_padded_sequence(x, lengths=lens, batch_first=False, enforce_sorted=False)\n",
        "        outputs, _ = self.lstm(rnn_inp)\n",
        "        ### Use the outputs and pass it through the pBLSTM blocks! ###\n",
        "        outputs, _, lens = self.pBLSTM1(outputs, lens)\n",
        "        outputs, _, lens = self.pBLSTM2(outputs, lens)\n",
        "        outputs, hidden, lens = self.pBLSTM3(outputs, lens)\n",
        "        linear_input, lens = utils.rnn.pad_packed_sequence(outputs)\n",
        "        linear_input = torch.transpose(linear_input, 0, 1)\n",
        "        keys = self.key_network(linear_input)\n",
        "        value = self.value_network(linear_input)\n",
        "        return torch.transpose(keys, 0, 1), torch.transpose(value, 0, 1), lens\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step, \n",
        "    thus we use LSTMCell instead of LSLTM here.\n",
        "    The output from the second LSTMCell can be used as query here for attention module.\n",
        "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
        "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
        "    '''\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, value_size=128, key_size=128, isAttended=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0).to(DEVICE)\n",
        "        self.lstm1 = nn.LSTMCell(input_size=embed_dim + value_size, hidden_size=hidden_dim).to(DEVICE)\n",
        "        self.lstm2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=key_size).to(DEVICE)\n",
        "        self.drop1 = LockedDropout(dropout = 0.5)\n",
        "        self.drop2 = LockedDropout(dropout = 0.5)\n",
        "        self.isAttended = isAttended\n",
        "        if (isAttended == True):\n",
        "            self.attention = Attention().to(DEVICE)\n",
        "        self.query_network = nn.Linear(embed_dim, key_size)\n",
        "        self.fc = nn.Linear(key_size + value_size, embed_dim)\n",
        "        self.tanh = nn.Hardtanh(inplace = True)\n",
        "        self.character_prob = nn.Linear(embed_dim, vocab_size)\n",
        "        self.character_prob.weight = self.embedding.weight\n",
        "\n",
        "    def forward(self, key, values, text=None, lens = None, isTrain=True):\n",
        "        '''\n",
        "        :param key :(T, N, key_size) Output of the Encoder Key projection layer\n",
        "        :param values: (T, N, value_size) Output of the Encoder Value projection layer\n",
        "        :param text: (N, text_len) Batch input of text with text_length\n",
        "        :param isTrain: Train or eval mode\n",
        "        :return predictions: Returns the character prediction probability \n",
        "        '''\n",
        "        batch_size = key.shape[1]\n",
        "\n",
        "        if isTrain:\n",
        "            text = torch.transpose(text, 0, 1)\n",
        "            max_len = text.shape[1]\n",
        "            embeddings = self.embedding(text)\n",
        "        elif text is not None:\n",
        "            text = torch.transpose(text, 0, 1)\n",
        "            max_len = 600\n",
        "            embeddings = self.embedding(text)\n",
        "        else:\n",
        "            max_len = 600\n",
        "\n",
        "        predictions = []\n",
        "        hidden_states = [None, None]\n",
        "        # prediction = torch.zeros(batch_size,1).to(DEVICE)\n",
        "        prediction = (torch.ones(batch_size, 1)*33).to(DEVICE)\n",
        "        context = values[0,:,:]\n",
        "        for i in range(max_len):\n",
        "            # * Implement Gumble noise and teacher forcing techniques \n",
        "            # * When attention is True, replace values[i,:,:] with the context you get from attention.\n",
        "            # * If you haven't implemented attention yet, then you may want to check the index and break \n",
        "            #   out of the loop so you do not get index out of range errors. \n",
        "\n",
        "            if isTrain:\n",
        "                # teacher forcing\n",
        "                if np.random.random_sample() > 0.9:\n",
        "                    char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "                else:\n",
        "                    if i == 0:\n",
        "                        char_embed = self.embedding(prediction.argmax(dim = 1))\n",
        "                    else:\n",
        "                        char_embed = embeddings[:, i, :]\n",
        "            # elif text is not None: # for random search\n",
        "            #     char_embed = embeddings[:,i,:]\n",
        "            else:\n",
        "                if text is not None and i == 0:\n",
        "                    char_embed = embeddings[:,i,:]\n",
        "                else:\n",
        "                    # prediction = Gumbel(prediction.to('cpu'), torch.tensor([0.5])).sample().to(DEVICE)\n",
        "                    char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "            inp = torch.cat([char_embed, context], dim=1)\n",
        "            inp = self.drop1(inp.unsqueeze(1)).squeeze(1)\n",
        "            hidden_states[0] = self.lstm1(inp, hidden_states[0])\n",
        "\n",
        "            inp_2 = hidden_states[0][0]\n",
        "            inp_2 = self.drop2(inp_2.unsqueeze(1)).squeeze(1)\n",
        "            hidden_states[1] = self.lstm2(inp_2, hidden_states[1])\n",
        "\n",
        "            ### Compute attention from the output of the second LSTM Cell ###\n",
        "            output = hidden_states[1][0]\n",
        "            context, attention = self.attention(output, torch.transpose(key, 0, 1), torch.transpose(values, 0, 1), lens)\n",
        "            fc_outputs = self.fc(torch.cat([output, context], dim=1))\n",
        "            fc_outputs = self.tanh(fc_outputs)\n",
        "            prediction = self.character_prob(fc_outputs)\n",
        "            predictions.append(prediction.unsqueeze(1))\n",
        "\n",
        "        return torch.cat(predictions, dim=1)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    '''\n",
        "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
        "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
        "    '''\n",
        "    def __init__(self, input_dim, vocab_size, embed_dim, encoder_hidden_dim, decoder_hidden_dim, value_size=128, key_size=128, isAttended=True):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, encoder_hidden_dim).to(DEVICE)\n",
        "        self.decoder = Decoder(vocab_size, embed_dim, decoder_hidden_dim).to(DEVICE)\n",
        "\n",
        "    def forward(self, speech_input, speech_len, text_input=None, isTrain=True):\n",
        "        key, value, lens = self.encoder(speech_input, speech_len)\n",
        "        if (isTrain == True):\n",
        "            predictions = self.decoder(key, value, text=text_input, lens=lens)\n",
        "        else:\n",
        "            predictions = self.decoder(key, value, text=text_input, lens=lens, isTrain=False)\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtv7mnkNhYqd"
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    # model.to(DEVICE)\n",
        "    start = time.time()\n",
        "    epoch_loss = 0.0\n",
        "    n_words = 0\n",
        "    # 1) Iterate through your loader\n",
        "    for i, (batch_data, batch_labels, feature_lengths, label_lengths) in enumerate(train_loader):\n",
        "        # 2) Use torch.autograd.set_detect_anomaly(True) to get notices about gradient explosion\n",
        "        \n",
        "        # 3) Set the inputs to the device.\n",
        "        batch_data = batch_data.to(DEVICE)\n",
        "        batch_labels = batch_labels.to(DEVICE)\n",
        "        # feature_lengths = feature_lengths.to(DEVICE)\n",
        "        label_lengths = label_lengths.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        # 4) Pass your inputs, and length of speech into the model.\n",
        "        outputs = model(speech_input=batch_data, speech_len=feature_lengths, text_input=batch_labels)\n",
        "        # 5) Generate a mask based on the lengths of the text to create a masked loss. \n",
        "        # 5.1) Ensure the mask is on the device and is the correct shape.\n",
        "        # mask = torch.zeros(batch_labels.size()).to(DEVICE)\n",
        "\n",
        "        mask = torch.arange(batch_labels.size(0)).reshape(-1, 1).to(DEVICE) < label_lengths.reshape(1, -1)\n",
        "        mask = torch.transpose(mask, 0, 1)\n",
        "        # mask = mask.contiguous().view(-1).to(DEVICE)\n",
        "        # 6) If necessary, reshape your predictions and origianl text input \n",
        "        # 6.1) Use .contiguous() if you need to. \n",
        "        outputs = outputs.permute(0, 2, 1)\n",
        "        batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "        # 7) Use the criterion to get the loss.\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        # 8) Use the mask to calculate a masked loss. \n",
        "        masked_loss = torch.sum(loss * mask)\n",
        "        # 9) Run the backward pass on the masked loss. \n",
        "        masked_loss.backward()\n",
        "        # 10) Use torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
        "        utils.clip_grad_norm_(model.parameters(), 2)\n",
        "        # 11) Take a step with your optimizer\n",
        "        optimizer.step()        \n",
        "        # 12) Normalize the masked loss\n",
        "        normalized_loss = float(masked_loss.item()) / int(torch.sum(mask).item())\n",
        "        epoch_loss += normalized_loss\n",
        "        n_words += int((batch_labels == 32).sum())\n",
        "        # 13) Optionally print the training loss after every N batches\n",
        "        # if i % 100 == 99:\n",
        "        #     print('Epoch: ', epoch+1, 'Train_loss: ', normalized_loss)\n",
        "        del batch_data\n",
        "        del batch_labels\n",
        "        del feature_lengths\n",
        "        del label_lengths\n",
        "        del outputs\n",
        "        del mask\n",
        "        del loss\n",
        "        del masked_loss\n",
        "        torch.cuda.empty_cache()\n",
        "    scheduler.step()\n",
        "    end = time.time()\n",
        "    perplexity = np.power(2, epoch_loss / n_words)\n",
        "    print('Epoch:', epoch+1, ' Train perplexity:', perplexity)\n",
        "\n",
        "def val(model, val_loader, criterion, epoch):\n",
        "    model.eval()\n",
        "    distance = 0\n",
        "    seq_len = 0\n",
        "    for batch_num, (batch_data, batch_labels, feature_lengths, label_lengths) in enumerate(val_loader):\n",
        "        batch_data = batch_data.to(DEVICE)\n",
        "        batch_labels = batch_labels.to(DEVICE)\n",
        "        label_lengths = label_lengths.to(DEVICE)\n",
        "        outputs = model(speech_input=batch_data, speech_len=feature_lengths, text_input=None, isTrain=False)\n",
        "        batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "        \n",
        "        for i in range(len(batch_labels)):\n",
        "            true_sentence = ''\n",
        "            for j in range(label_lengths[i]):\n",
        "                true_sentence += LETTER_LIST[batch_labels[i][j]]\n",
        "\n",
        "            predict_sentence = ''\n",
        "            for j in range(len(outputs[i])):                \n",
        "                predict_sentence += LETTER_LIST[outputs[i][j].argmax()]\n",
        "                if outputs[i][j].argmax() == 34:\n",
        "                    break\n",
        "            # if i % 100 == 0:\n",
        "            #     print(true_sentence, predict_sentence, levenshtein_distance(true_sentence, predict_sentence))\n",
        "            distance += levenshtein_distance(true_sentence, predict_sentence)\n",
        "            seq_len += 1\n",
        "        del batch_data\n",
        "        del batch_labels\n",
        "        del feature_lengths\n",
        "        del label_lengths\n",
        "        del outputs\n",
        "        torch.cuda.empty_cache()\n",
        "    avg_dist = distance / seq_len\n",
        "    print('Epoch:', epoch+1, ' Average Levenshtein distance:', avg_dist)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXANAnITcuXp"
      },
      "source": [
        "# random search, not used\n",
        "def test(model, test_loader, epoch):\n",
        "    ### Write your test code here! ###\n",
        "    pred_total = []\n",
        "    count = 0\n",
        "    for batch_num, (batch_data, feature_lengths) in enumerate(test_loader):\n",
        "        batch_data = batch_data.cuda()\n",
        "        sos = torch.Tensor([33] * batch_data.shape[1]).reshape(-1, 1).long().cuda()\n",
        "        outputs = model(batch_data, feature_lengths, text_input=sos, isTrain=False)\n",
        "        for i in range(len(outputs)):\n",
        "            pred_sentences = []\n",
        "            for sample in range(100):\n",
        "                pred_sentence = []\n",
        "                for j in range(len(outputs[i])):\n",
        "\n",
        "                    prob = outputs[i][j]\n",
        "                    prob = F.softmax(prob)\n",
        "                    # print(prob, prob.shape)                \n",
        "                    pred_char = int(torch.multinomial(prob, 1).item())\n",
        "                    pred_sentence.append(pred_char)\n",
        "                    if pred_char == 34:\n",
        "                        break\n",
        "                pred_sentences.append(torch.tensor(pred_sentence).cuda())\n",
        "            lengths = [len(sentence) for sentence in pred_sentences]\n",
        "            losses = []\n",
        "            for i in range(len(pred_sentences)):\n",
        "                outputs_test = outputs[:, :lengths[i], :]\n",
        "                sentence = pred_sentences[i]\n",
        "                outputs_test = outputs_test.contiguous().view(-1, outputs.size(-1))\n",
        "                loss = criterion(outputs_test, sentence)\n",
        "                losses.append(loss.sum().item())\n",
        "            best_index = np.argmin(np.array(losses))\n",
        "            best_sentences = ''.join([LETTER_LIST[idx] for idx in pred_sentences[best_index]])\n",
        "            if '<eos>' not in best_sentences:\n",
        "                best_sentences += '<eos>'\n",
        "            best_sentences = best_sentences.replace('<sos>', '<sos> ')\n",
        "            pred_total.append(best_sentences)\n",
        "            count += 1\n",
        "            # if count == 100:\n",
        "            #     print(best_index, best_sentences)\n",
        "            print(best_index, best_sentences)\n",
        "\n",
        "    return pred_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4NtCkWvZZXX"
      },
      "source": [
        "# greedy search\r\n",
        "def test(model, test_loader, epoch):\r\n",
        "    ### Write your test code here! ###\r\n",
        "    pred_total = []\r\n",
        "    for batch_num, (batch_data, feature_lengths) in enumerate(test_loader):\r\n",
        "        batch_data = batch_data.cuda()\r\n",
        "        outputs, _ = model(speech_input=batch_data, speech_len=feature_lengths, text_input=None, isTrain=False)\r\n",
        "        for i in range(batch_data.shape[1]):\r\n",
        "            predict_sentence = ''\r\n",
        "            for j in range(len(outputs[i])):\r\n",
        "                if outputs[i][j].argmax() == 34:\r\n",
        "                    break\r\n",
        "                predict_sentence += LETTER_LIST[outputs[i][j].argmax()]\r\n",
        "            pred_total.append(predict_sentence)\r\n",
        "    return pred_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMdijF9zx60a"
      },
      "source": [
        "LETTER_LIST = ['<pad>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
        "               'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ','<sos>','<eos>']\n",
        "speech_train, speech_valid, speech_test, transcript_train, transcript_valid = load_data()\n",
        "character_text_train = transform_letter_to_index(transcript_train, LETTER_LIST)\n",
        "character_text_valid = transform_letter_to_index(transcript_valid, LETTER_LIST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irUcSVO7yAkS"
      },
      "source": [
        "batch_size = 64 if DEVICE == 'cuda' else 1\n",
        "\n",
        "train_dataset = Speech2TextDataset(speech_train, character_text_train)\n",
        "val_dataset = Speech2TextDataset(speech_valid, character_text_valid)\n",
        "test_dataset = Speech2TextDataset(speech_test, None, False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_train)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_train)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQI_jAXkcjWU"
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "model = Seq2Seq(input_dim=40, vocab_size=len(LETTER_LIST), embed_dim=256, encoder_hidden_dim=256, decoder_hidden_dim=512).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-6)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.95)\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "nepochs = 15\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzo1NJAnQs22",
        "outputId": "ae70ec50-14d3-4d65-805d-caa41d08d3d1"
      },
      "source": [
        "model.load_state_dict(torch.load('model_e35.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CIaX3Niccsl9"
      },
      "source": [
        "for epoch in range(nepochs):\n",
        "    train(model, train_loader, criterion, optimizer, scheduler, epoch)\n",
        "    val(model, val_loader, criterion, epoch)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmLpU25UyD4D"
      },
      "source": [
        "# Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxvSXuRB-zwm"
      },
      "source": [
        "pred = test(model, test_loader, 0)\n",
        "print(pred[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVzP61aCU1K9",
        "outputId": "c35eeca4-6365-426a-fb3a-7cb5a98a163f"
      },
      "source": [
        "print(len(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnlF57-hUP4C"
      },
      "source": [
        "# generate submission.csv\n",
        "with open('submission.csv', 'w') as f:\n",
        "  f.write('id,label\\n')\n",
        "  for i in range(len(pred)):\n",
        "    f.write(str(i) + ',' + pred[i]+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT7V7kTjUiBi"
      },
      "source": [
        "!kaggle competitions submit -c 11-785-fall-20-homework-4-part-2 -f submission.csv -m \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE4OxH-N2P3Y"
      },
      "source": [
        "torch.save(model.state_dict(), \"model_e35.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IILIihLCcbMb"
      },
      "source": [
        "from matplotlib.lines import Line2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_attn_flow(attn_mask, path):\n",
        "    plt.imsave(path, attn_mask, cmap='hot')\n",
        "    return plt\n",
        "\n",
        "def plot_grad_flow(named_parameters, path):\n",
        "    ave_grads = []\n",
        "    max_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            if(p is not None):\n",
        "                layers.append(n)\n",
        "                ave_grads.append(p.grad.abs().mean())\n",
        "                max_grads.append(p.grad.abs().max())\n",
        "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    #plt.tight_layout()\n",
        "    plt.grid(True)\n",
        "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\n",
        "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
        "    plt.show()\n",
        "    plt.savefig(path)\n",
        "    return plt, max_grads\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}